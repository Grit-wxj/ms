# -*- coding: utf-8 -*-
import subprocess
import sys
import importlib.util
import os
import json
import argparse
import platform
import warnings
from datetime import datetime

# --- è‡ªåŠ¨ä¾èµ–æ£€æŸ¥ä¸å®‰è£… ---
def check_and_install_dependencies():
    """è‡ªåŠ¨æ£€æµ‹å¹¶å®‰è£…æ‰€éœ€çš„ Python åº“"""
    required_packages = [
        ("opencv-python", "cv2"),
        ("numpy", "numpy"),
        ("matplotlib", "matplotlib"),
        ("librosa", "librosa"),
        ("pillow", "PIL"),
        ("static-ffmpeg", "static_ffmpeg")
    ]

    print("[-] æ­£åœ¨æ£€æŸ¥ç¯å¢ƒä¾èµ–...")
    for package_name, import_name in required_packages:
        if importlib.util.find_spec(import_name) is None:
            print(f"[!] æœªæ£€æµ‹åˆ°åº“ '{package_name}' ({import_name})ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
                print(f"[+] '{package_name}' å®‰è£…æˆåŠŸ")
            except subprocess.CalledProcessError:
                print(f"[x] '{package_name}' å®‰è£…å¤±è´¥ã€‚è¯·å°è¯•æ‰‹åŠ¨è¿è¡Œ: pip install {package_name}")
                sys.exit(1)
    print("[-] æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥é€šè¿‡ã€‚\n")

check_and_install_dependencies()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
from PIL import Image, ImageChops, ImageEnhance, ImageStat
import static_ffmpeg

# è‡ªåŠ¨é…ç½® FFmpeg
print("[-] æ­£åœ¨åˆå§‹åŒ– FFmpeg ç¯å¢ƒ...")
try:
    static_ffmpeg.add_paths()
    print("[+] FFmpeg ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"[!] FFmpeg åˆå§‹åŒ–è­¦å‘Š: {e}")

# é…ç½®ä¸­æ–‡å­—ä½“
def configure_matplotlib_fonts():
    system_name = platform.system()
    if system_name == 'Windows':
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial']
    elif system_name == 'Darwin':
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC']
    else:
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Droid Sans Fallback']
    plt.rcParams['axes.unicode_minus'] = False

configure_matplotlib_fonts()

def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º åˆ†:ç§’.æ¯«ç§’ æ ¼å¼"""
    m = int(seconds // 60)
    s = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{m:02d}åˆ†{s:02d}ç§’{ms:03d}"

class MediaForensicsTool:
    def __init__(self, file_path):
        self.file_path = file_path
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        print(f"[*] å·²åŠ è½½æ–‡ä»¶: {file_path}")

    def analyze_metadata(self):
        print("\n--- [1] å¼€å§‹å…ƒæ•°æ®åˆ†æ ---")
        try:
            cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', '-show_streams', self.file_path]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                 raise Exception("FFprobe æ‰§è¡Œå¤±è´¥")

            data = json.loads(result.stdout)
            tags = data.get('format', {}).get('tags', {})
            
            # æ£€æŸ¥å¸¸è§çš„ç¼–è¾‘è½¯ä»¶ç­¾å
            suspicious_keywords = ['Lavf', 'Adobe', 'Premiere', 'Final Cut', 'HandBrake', 'DaVinci', 'CapCut']
            encoder = tags.get('encoder', '')
            
            # æ·±åº¦æŸ¥æ‰¾
            if not encoder:
                for s in data.get('streams', []):
                    encoder = s.get('tags', {}).get('encoder', encoder)

            print(f"    ç¼–ç å™¨ä¿¡æ¯: {encoder if encoder else 'æœªæ‰¾åˆ°'}")
            
            found = False
            if encoder:
                for k in suspicious_keywords:
                    if k.lower() in encoder.lower():
                        print(f"[!] è­¦å‘Š: å‘ç°åæœŸè½¯ä»¶ç­¾å -> {k}")
                        found = True
            
            if not found:
                print("[âˆš] å…ƒæ•°æ®æ´å‡€åº¦: è¾ƒé«˜ (æœªå‘ç°æ˜æ˜¾åæœŸè½¯ä»¶æ ‡ç­¾)")
                
        except Exception as e:
            print(f"[!] å…ƒæ•°æ®æå–å¤±è´¥: {e}")

    def detect_video_cuts_smart(self):
        """
        æ™ºèƒ½ç‰ˆï¼šè§†é¢‘é•œå¤´åˆ†å‰²æ£€æµ‹
        æ”¹ç”¨ [æ’åº + å±€éƒ¨æå€¼] ç­–ç•¥ï¼Œè€Œéå•çº¯çš„é˜ˆå€¼æˆªæ–­ã€‚
        èƒ½æ›´å‡†ç¡®åœ°æŠ“å‡ºæœ€æ˜¾è‘—çš„é‚£ä¸ªæ‹¼æ¥ç‚¹ã€‚
        """
        print("\n--- [2] å¼€å§‹è§†é¢‘ç”»é¢å‰ªè¾‘ç‚¹æ‰«æ (æ™ºèƒ½æ’åºç®—æ³•) ---")
        print("    æ­£åœ¨é€å¸§è®¡ç®—è‰²å½©ç›¸å…³æ€§å¹¶å¯»æ‰¾çªå˜æå€¼...")
        
        cap = cv2.VideoCapture(self.file_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        
        ret, prev_frame = cap.read()
        if not ret:
            print("[!] æ— æ³•è¯»å–è§†é¢‘å¸§")
            return []

        # è½¬æ¢ä¸º HSV ç©ºé—´ï¼Œè®¡ç®—ç›´æ–¹å›¾
        prev_hsv = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV)
        prev_hist = cv2.calcHist([prev_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
        cv2.normalize(prev_hist, prev_hist, 0, 1, cv2.NORM_MINMAX)
        
        frame_idx = 0
        diff_scores = [] # å­˜å‚¨ (frame_time, correlation_score)
        
        # æ­¥è¿›æ‰«æï¼Œæ¯å¸§éƒ½çœ‹ï¼Œä¿è¯ç²¾åº¦
        while True:
            ret, curr_frame = cap.read()
            if not ret:
                break
            frame_idx += 1
            
            # ä¸ºäº†æ€§èƒ½ï¼Œå¯ä»¥è·³è¿‡éƒ¨åˆ†å¸§ï¼Œä½†åœ¨å¯»æ‰¾å•ä¸€æ‹¼æ¥ç‚¹æ—¶å»ºè®®é€å¸§æˆ–éš”å¸§
            if frame_idx % 2 != 0: 
                continue

            curr_hsv = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2HSV)
            curr_hist = cv2.calcHist([curr_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
            cv2.normalize(curr_hist, curr_hist, 0, 1, cv2.NORM_MINMAX)
            
            # è®¡ç®—ç›´æ–¹å›¾ç›¸å…³æ€§ (1.0 = ç›¸åŒ, 0.0 = å®Œå…¨ä¸åŒ)
            # æˆ‘ä»¬ç”¨ 1 - correlation ä½œä¸ºâ€œå·®å¼‚åˆ†â€ï¼Œåˆ†æ•°è¶Šé«˜å·®å¼‚è¶Šå¤§
            correlation = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_CORREL)
            diff_score = 1.0 - correlation
            
            timestamp = frame_idx / fps
            diff_scores.append((timestamp, diff_score))
            
            prev_hist = curr_hist
            
            if frame_idx % 100 == 0:
                print(f"    ...å·²æ‰«æ {format_timestamp(timestamp)}", end="\r")

        cap.release()
        print("\n    æ‰«æå®Œæˆï¼Œæ­£åœ¨è®¡ç®—æ˜¾è‘—æ€§æ’å...")
        
        if not diff_scores:
            return []

        # --- æ™ºèƒ½åˆ†æé€»è¾‘ ---
        # 1. æ‰¾å‡ºå·®å¼‚åˆ†æœ€é«˜çš„ç‚¹ (å·®å¼‚è¶Šå¤§ï¼Œè¶Šå¯èƒ½æ˜¯ç¡¬åˆ‡)
        # æ’åºï¼šä»å¤§åˆ°å°
        sorted_scores = sorted(diff_scores, key=lambda x: x[1], reverse=True)
        
        # 2. è¿‡æ»¤é‚»è¿‘ç‚¹ (åªä¿ç•™å±€éƒ¨æœ€å¤§çš„é‚£ä¸ªå³°å€¼)
        final_cuts = []
        for t, score in sorted_scores:
            # å¦‚æœåˆ†æ•°å¤ªä½ï¼ˆå°äº0.15ï¼Œå³ç›¸å…³æ€§å¤§äº0.85ï¼‰ï¼Œè¯´æ˜åªæ˜¯æ™®é€šè¿é•œï¼Œå¿½ç•¥
            if score < 0.15: 
                continue
                
            # æ£€æŸ¥æ˜¯å¦ä¸å·²æœ‰çš„ç‚¹å¤ªè¿‘ (1.5ç§’å†…)
            is_near = False
            for existing_t, _ in final_cuts:
                if abs(t - existing_t) < 1.5:
                    is_near = True
                    break
            
            if not is_near:
                final_cuts.append((t, score))
                if len(final_cuts) >= 5: # åªå–å‰5ä¸ªæœ€å¯ç–‘çš„
                    break
        
        print(f"    [è§†é¢‘åˆ†æç»“æœ]")
        if not final_cuts:
            print("    - ç»“æœ: ç”»é¢å¹³æ»‘ï¼Œæœªæ£€æµ‹åˆ°æ˜¾è‘—æ‹¼æ¥ã€‚")
            return []
        else:
            print(f"    - ç»“æœ: å‘ç°æ½œåœ¨çªå˜ç‚¹ï¼ŒæŒ‰ã€ç½®ä¿¡åº¦ã€‘ä»é«˜åˆ°ä½æ’åºï¼š")
            for i, (t, score) in enumerate(final_cuts):
                # å·®å¼‚åˆ†è¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
                confidence = min(score * 100 + 20, 99.9) 
                print(f"      [{i+1}] æ—¶é—´: {format_timestamp(t)} | å·®å¼‚å¼ºåº¦: {score:.3f}")
            
            # è¿”å›æ—¶é—´ç‚¹åˆ—è¡¨
            return [t for t, score in final_cuts]

    def perform_ela_on_frame(self, frame_time_sec=1.0):
        print(f"\n--- [3] ELA ç¯¡æ”¹ç—•è¿¹æ·±åº¦åˆ†æ (é‡‡æ ·ç‚¹: {format_timestamp(frame_time_sec)}) ---")
        
        cap = cv2.VideoCapture(self.file_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(fps * frame_time_sec))
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            print("[!] æ— æ³•è¯»å–è¯¥å¸§")
            return

        original_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        temp_filename = "temp_ela.jpg"
        original_img.save(temp_filename, "JPEG", quality=90)
        compressed_img = Image.open(temp_filename)
        
        ela_img = ImageChops.difference(original_img, compressed_img)
        
        # --- è‡ªåŠ¨åŒ–è¯„åˆ†é€»è¾‘ ---
        stat = ImageStat.Stat(ela_img)
        mean_diff = sum(stat.mean) / len(stat.mean)
        
        # å½’ä¸€åŒ–è¯„åˆ†
        tamper_score = min(mean_diff * 10, 100)
        
        print(f"    [ELA é‡åŒ–è¯„åˆ†]")
        print(f"    - å¼‚å¸¸ç³»æ•°: {tamper_score:.2f}/100")
        
        if tamper_score > 30:
            print("    - âš ï¸ è­¦å‘Š: æ£€æµ‹åˆ°å¼‚å¸¸çš„å‹ç¼©ä¼ªå½±ï¼Œè¯¥å¸§å¯èƒ½åŒ…å«åˆæˆå…ƒç´ ï¼")
        else:
            print("    - çŠ¶æ€: å‹ç¼©ç‰¹å¾å‡åŒ€ï¼Œæœªè§æ˜æ˜¾å±€éƒ¨ç¯¡æ”¹ã€‚")

        # è§†è§‰å¢å¼º
        extrema = ela_img.getextrema()
        max_diff_val = max([ex[1] for ex in extrema])
        scale = 255.0 / (max_diff_val if max_diff_val > 0 else 1) * 15 
        ela_img = ImageEnhance.Brightness(ela_img).enhance(scale)
        
        # ä¿å­˜
        output_filename = f"ela_check.png"
        
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.title("åŸå§‹å¸§")
        plt.imshow(original_img)
        plt.axis('off')
        plt.subplot(1, 2, 2)
        plt.title(f"ELA (å¼‚å¸¸åˆ†: {tamper_score:.1f})")
        plt.imshow(ela_img)
        plt.axis('off')
        
        try:
            plt.savefig(output_filename)
            print(f"    [å›¾ç‰‡] ELAåˆ†æå›¾å·²ä¿å­˜è‡³: {output_filename}")
        except Exception:
            pass
        
        if os.path.exists(temp_filename):
            try: os.remove(temp_filename)
            except: pass

    def analyze_audio_smart(self):
        """
        æ™ºèƒ½ç‰ˆï¼šéŸ³é¢‘ç‰¹å¾åˆ†æ
        åŒæ ·é‡‡ç”¨æ’åºç­–ç•¥ï¼Œæ‰¾å‡ºæœ€çªå…€çš„éŸ³é¢‘å˜åŒ–ç‚¹ã€‚
        """
        print("\n--- [4] å¼€å§‹éŸ³é¢‘ç‰¹å¾æ˜¾è‘—æ€§åˆ†æ ---")
        try:
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore")
                y, sr = librosa.load(self.file_path, duration=60)
            
            # 1. èƒ½é‡çªå˜ (Onset Strength)
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            times = librosa.frames_to_time(np.arange(len(onset_env)), sr=sr)
            
            # å°† (æ—¶é—´, å¼ºåº¦) æ‰“åŒ…
            onset_points = []
            for i, strength in enumerate(onset_env):
                onset_points.append((times[i], strength))
            
            # 2. æ’åºå¹¶è¿‡æ»¤
            # æŒ‰å¼ºåº¦é™åº
            sorted_onsets = sorted(onset_points, key=lambda x: x[1], reverse=True)
            
            final_audio_cuts = []
            # è·å–å¹³å‡å¼ºåº¦ä½œä¸ºåŸºå‡†
            avg_strength = np.mean(onset_env)
            std_strength = np.std(onset_env)
            threshold_base = avg_strength + 3 * std_strength
            
            for t, strength in sorted_onsets:
                if strength < threshold_base: # å¿½ç•¥ä½äºèƒŒæ™¯å™ªéŸ³æ³¢åŠ¨çš„
                    continue
                    
                # è·ç¦»è¿‡æ»¤ (1ç§’)
                is_near = False
                for existing_t, _ in final_audio_cuts:
                    if abs(t - existing_t) < 1.0:
                        is_near = True
                        break
                
                if not is_near:
                    final_audio_cuts.append((t, strength))
                    if len(final_audio_cuts) >= 5:
                        break
            
            print(f"    [éŸ³é¢‘åˆ†æç»“æœ]")
            if not final_audio_cuts:
                print("    - ç»“æœ: éŸ³é¢‘å¹³ç¨³ã€‚")
                return []
            else:
                print(f"    - ç»“æœ: å‘ç°æ½œåœ¨æ–­å±‚ï¼ŒæŒ‰ã€æ˜¾è‘—æ€§ã€‘ä»é«˜åˆ°ä½æ’åºï¼š")
                for i, (t, strength) in enumerate(final_audio_cuts):
                    print(f"      [{i+1}] æ—¶é—´: {format_timestamp(t)} | çªå˜å¼ºåº¦: {strength:.2f}")
                
            # ç»˜å›¾
            plt.figure(figsize=(12, 6))
            D = librosa.stft(y)
            S_db = librosa.amplitude_to_db(np.abs(D), ref=np.max)
            librosa.display.specshow(S_db, sr=sr, x_axis='time', y_axis='log')
            plt.colorbar(format='%+2.0f dB')
            plt.title('éŸ³é¢‘é¢‘è°±ä¸ Top ç–‘ä¼¼ç‚¹')
            for t, _ in final_audio_cuts:
                plt.axvline(x=t, color='r', linestyle='--', alpha=0.8, linewidth=1.5)
            plt.tight_layout()
            plt.savefig("audio_check_smart.png")
            print(f"    [å›¾ç‰‡] éŸ³é¢‘åˆ†æå›¾å·²ä¿å­˜è‡³: audio_check_smart.png")
            
            return [t for t, s in final_audio_cuts]
            
        except Exception as e:
            print(f"[!] éŸ³é¢‘åˆ†æä¸­æ–­: {e}")
            return []

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--file", type=str, help="æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    target_file = args.file
    if not target_file:
        print("\n=== éŸ³è§†é¢‘æ‹¼æ¥å–è¯å·¥å…· (æ™ºèƒ½æ’åºç‰ˆ) ===")
        print("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„:")
        target_file = input(">>> ").strip().strip("'").strip('"')

    if target_file and os.path.exists(target_file):
        tool = MediaForensicsTool(target_file)
        
        # 1. å…ƒæ•°æ®
        tool.analyze_metadata()
        
        # 2. è§†é¢‘æ£€æµ‹ (æ™ºèƒ½æ’åº)
        video_cuts = tool.detect_video_cuts_smart()
        
        # 3. ELA åˆ†æ (åªåˆ†æ Top 1 å’Œ Top 2ï¼Œå› ä¸ºç”¨æˆ·è¯´åªæœ‰ä¸€å¤„æ‹¼æ¥)
        check_points = [1.0]
        if video_cuts:
            check_points = video_cuts[:2] 
            print(f"\n[i] é‡ç‚¹å¯¹å‰ {len(check_points)} ä¸ªå¯ç–‘ç‚¹è¿›è¡Œ ELA ç¯¡æ”¹éªŒè¯...")
        
        for t in check_points:
            tool.perform_ela_on_frame(t)
        
        # 4. éŸ³é¢‘æ£€æµ‹ (æ™ºèƒ½æ’åº)
        audio_cuts = tool.analyze_audio_smart()
        
        # 5. ç»¼åˆåˆ¤å®š
        print("\n=== ğŸ æœ€ç»ˆå–è¯ç»“è®º (åŸºäº Top æ’å) ===")
        
        # å¯»æ‰¾æœ€å¼ºåŒ¹é… (Top 1 Video vs Top 1 Audio)
        primary_match = False
        if video_cuts and audio_cuts:
            v_top1 = video_cuts[0]
            # æ£€æŸ¥éŸ³é¢‘å‰3åé‡Œæœ‰æ²¡æœ‰å’Œè§†é¢‘ç¬¬1ååŒ¹é…çš„
            for a_cut in audio_cuts[:3]: 
                if abs(v_top1 - a_cut) < 1.0:
                    print(f"âœ… ã€ç¡®å‡¿è¯æ®ã€‘ è§†é¢‘æœ€å¼ºçªå˜ç‚¹ä¸éŸ³é¢‘æ–­å±‚é‡åˆï¼")
                    print(f"   >>> æ‹¼æ¥ç‚¹æå¤§æ¦‚ç‡åœ¨: {format_timestamp(v_top1)} <<<")
                    primary_match = True
                    break
        
        if not primary_match:
            if video_cuts:
                print(f"âš ï¸ ã€ç–‘ä¼¼æ‹¼æ¥ã€‘ è§†é¢‘ç”»é¢åœ¨ {format_timestamp(video_cuts[0])} å¤„æœ‰æœ€å¤§çªå˜ã€‚")
            if audio_cuts:
                print(f"âš ï¸ ã€ç–‘ä¼¼æ‹¼æ¥ã€‘ éŸ³é¢‘æ³¢å½¢åœ¨ {format_timestamp(audio_cuts[0])} å¤„æœ‰æœ€å¤§æ–­å±‚ã€‚")
                
            print("â„¹ï¸  å¦‚æœä¸Šè¿°ä¸¤ä¸ªæ—¶é—´ç‚¹æ¥è¿‘ï¼Œå³ä¸ºæ‹¼æ¥å¤„ã€‚å¦‚æœä¸æ¥è¿‘ï¼Œå¯èƒ½æ˜¯ç”»å¤–éŸ³å‰ªè¾‘ã€‚")

    else:
        print("[!] æ–‡ä»¶ä¸å­˜åœ¨")
