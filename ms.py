# -*- coding: utf-8 -*-
import subprocess
import sys
import importlib.util
import os
import json
import argparse
import platform
import warnings
from datetime import datetime

# --- è‡ªåŠ¨ä¾èµ–æ£€æŸ¥ä¸å®‰è£… ---
def check_and_install_dependencies():
    """è‡ªåŠ¨æ£€æµ‹å¹¶å®‰è£…æ‰€éœ€çš„ Python åº“"""
    required_packages = [
        ("opencv-python", "cv2"),
        ("numpy", "numpy"),
        ("matplotlib", "matplotlib"),
        ("librosa", "librosa"),
        ("pillow", "PIL"),
        ("static-ffmpeg", "static_ffmpeg")
    ]

    print("[-] æ­£åœ¨æ£€æŸ¥ç¯å¢ƒä¾èµ–...")
    for package_name, import_name in required_packages:
        if importlib.util.find_spec(import_name) is None:
            print(f"[!] æœªæ£€æµ‹åˆ°åº“ '{package_name}' ({import_name})ï¼Œæ­£åœ¨å°è¯•è‡ªåŠ¨å®‰è£…...")
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", package_name])
                print(f"[+] '{package_name}' å®‰è£…æˆåŠŸ")
            except subprocess.CalledProcessError:
                print(f"[x] '{package_name}' å®‰è£…å¤±è´¥ã€‚è¯·å°è¯•æ‰‹åŠ¨è¿è¡Œ: pip install {package_name}")
                sys.exit(1)
    print("[-] æ‰€æœ‰ä¾èµ–åº“æ£€æŸ¥é€šè¿‡ã€‚\n")

check_and_install_dependencies()

import cv2
import numpy as np
import matplotlib.pyplot as plt
import librosa
import librosa.display
from PIL import Image, ImageChops, ImageEnhance, ImageStat
import static_ffmpeg

# è‡ªåŠ¨é…ç½® FFmpeg
print("[-] æ­£åœ¨åˆå§‹åŒ– FFmpeg ç¯å¢ƒ...")
try:
    static_ffmpeg.add_paths()
    print("[+] FFmpeg ç¯å¢ƒåˆå§‹åŒ–æˆåŠŸ")
except Exception as e:
    print(f"[!] FFmpeg åˆå§‹åŒ–è­¦å‘Š: {e}")

# é…ç½®ä¸­æ–‡å­—ä½“
def configure_matplotlib_fonts():
    system_name = platform.system()
    if system_name == 'Windows':
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'SimSun', 'Arial']
    elif system_name == 'Darwin':
        plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'PingFang SC']
    else:
        plt.rcParams['font.sans-serif'] = ['WenQuanYi Micro Hei', 'Droid Sans Fallback']
    plt.rcParams['axes.unicode_minus'] = False

configure_matplotlib_fonts()

def format_timestamp(seconds):
    """å°†ç§’æ•°è½¬æ¢ä¸º åˆ†:ç§’.æ¯«ç§’ æ ¼å¼"""
    m = int(seconds // 60)
    s = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{m:02d}åˆ†{s:02d}ç§’{ms:03d}"

class MediaForensicsTool:
    def __init__(self, file_path):
        self.file_path = file_path
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        print(f"[*] å·²åŠ è½½æ–‡ä»¶: {file_path}")
        
        # åª’ä½“ç±»å‹æ ‡å¿—ä½
        self.has_video = False
        self.has_audio = False
        self.duration = 0

    def analyze_metadata(self):
        print("\n--- [1] å¼€å§‹å…ƒæ•°æ®åŠåª’ä½“ç±»å‹åˆ†æ ---")
        try:
            cmd = ['ffprobe', '-v', 'quiet', '-print_format', 'json', '-show_format', '-show_streams', self.file_path]
            result = subprocess.run(cmd, capture_output=True, text=True)
            if result.returncode != 0:
                 raise Exception("FFprobe æ‰§è¡Œå¤±è´¥")

            data = json.loads(result.stdout)
            format_info = data.get('format', {})
            tags = format_info.get('tags', {})
            self.duration = float(format_info.get('duration', 0))
            
            # æ£€æµ‹æµç±»å‹
            streams = data.get('streams', [])
            for s in streams:
                if s['codec_type'] == 'video':
                    self.has_video = True
                elif s['codec_type'] == 'audio':
                    self.has_audio = True

            # æ‰“å°åŸºç¡€ä¿¡æ¯
            file_type = "æœªçŸ¥"
            if self.has_video and self.has_audio: file_type = "è§†é¢‘ (å«éŸ³é¢‘)"
            elif self.has_video: file_type = "çº¯è§†é¢‘ (æ— éŸ³é¢‘)"
            elif self.has_audio: file_type = "çº¯éŸ³é¢‘ (MP3/WAVç­‰)"
            
            print(f"    æ£€æµ‹ç±»å‹: ã€{file_type}ã€‘")
            print(f"    æ—¶é•¿: {self.duration} ç§’")
            print(f"    å®¹å™¨æ ¼å¼: {format_info.get('format_name')}")

            # æ£€æŸ¥å¸¸è§çš„ç¼–è¾‘è½¯ä»¶ç­¾å
            suspicious_keywords = ['Lavf', 'Adobe', 'Premiere', 'Final Cut', 'HandBrake', 'DaVinci', 'CapCut', 'LAME']
            encoder = tags.get('encoder', '')
            
            if not encoder:
                for s in streams:
                    encoder = s.get('tags', {}).get('encoder', encoder)

            print(f"    ç¼–ç å™¨ä¿¡æ¯: {encoder if encoder else 'æœªæ‰¾åˆ°'}")
            
            found = False
            if encoder:
                for k in suspicious_keywords:
                    if k.lower() in encoder.lower():
                        print(f"[!] è­¦å‘Š: å‘ç°åæœŸè½¯ä»¶ç­¾å -> {k}")
                        found = True
            
            if not found:
                print("[âˆš] å…ƒæ•°æ®æ´å‡€åº¦: è¾ƒé«˜")
                
        except Exception as e:
            print(f"[!] å…ƒæ•°æ®æå–å¤±è´¥: {e}")

    def detect_video_cuts_smart(self):
        """
        æ™ºèƒ½ç‰ˆï¼šè§†é¢‘é•œå¤´åˆ†å‰²æ£€æµ‹
        """
        if not self.has_video:
            return []

        print("\n--- [2] å¼€å§‹è§†é¢‘ç”»é¢å‰ªè¾‘ç‚¹æ‰«æ (æ™ºèƒ½æ’åºç®—æ³•) ---")
        print("    æ­£åœ¨é€å¸§è®¡ç®—è‰²å½©ç›¸å…³æ€§å¹¶å¯»æ‰¾çªå˜æå€¼...")
        
        cap = cv2.VideoCapture(self.file_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        ret, prev_frame = cap.read()
        if not ret:
            print("[!] æ— æ³•è¯»å–è§†é¢‘å¸§")
            return []

        prev_hsv = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2HSV)
        prev_hist = cv2.calcHist([prev_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
        cv2.normalize(prev_hist, prev_hist, 0, 1, cv2.NORM_MINMAX)
        
        frame_idx = 0
        diff_scores = [] 
        
        while True:
            ret, curr_frame = cap.read()
            if not ret:
                break
            frame_idx += 1
            
            if frame_idx % 2 != 0: 
                continue

            curr_hsv = cv2.cvtColor(curr_frame, cv2.COLOR_BGR2HSV)
            curr_hist = cv2.calcHist([curr_hsv], [0, 1], None, [180, 256], [0, 180, 0, 256])
            cv2.normalize(curr_hist, curr_hist, 0, 1, cv2.NORM_MINMAX)
            
            correlation = cv2.compareHist(prev_hist, curr_hist, cv2.HISTCMP_CORREL)
            diff_score = 1.0 - correlation
            
            timestamp = frame_idx / fps
            diff_scores.append((timestamp, diff_score))
            
            prev_hist = curr_hist
            
            if frame_idx % 100 == 0:
                print(f"    ...å·²æ‰«æ {format_timestamp(timestamp)}", end="\r")

        cap.release()
        print("\n    æ‰«æå®Œæˆï¼Œæ­£åœ¨è®¡ç®—æ˜¾è‘—æ€§æ’å...")
        
        if not diff_scores:
            return []

        sorted_scores = sorted(diff_scores, key=lambda x: x[1], reverse=True)
        
        final_cuts = []
        for t, score in sorted_scores:
            if score < 0.15: 
                continue
            is_near = False
            for existing_t, _ in final_cuts:
                if abs(t - existing_t) < 1.5:
                    is_near = True
                    break
            if not is_near:
                final_cuts.append((t, score))
                if len(final_cuts) >= 5: 
                    break
        
        print(f"    [è§†é¢‘åˆ†æç»“æœ]")
        if not final_cuts:
            print("    - ç»“æœ: ç”»é¢å¹³æ»‘ï¼Œæœªæ£€æµ‹åˆ°æ˜¾è‘—æ‹¼æ¥ã€‚")
            return []
        else:
            print(f"    - ç»“æœ: å‘ç°æ½œåœ¨çªå˜ç‚¹ï¼ŒæŒ‰ã€ç½®ä¿¡åº¦ã€‘ä»é«˜åˆ°ä½æ’åºï¼š")
            for i, (t, score) in enumerate(final_cuts):
                confidence = min(score * 100 + 20, 99.9) 
                print(f"      [{i+1}] æ—¶é—´: {format_timestamp(t)} | å·®å¼‚å¼ºåº¦: {score:.3f}")
            return [t for t, score in final_cuts]

    def perform_ela_on_frame(self, frame_time_sec=1.0):
        if not self.has_video:
            return

        print(f"\n--- [3] ELA ç¯¡æ”¹ç—•è¿¹æ·±åº¦åˆ†æ (é‡‡æ ·ç‚¹: {format_timestamp(frame_time_sec)}) ---")
        
        cap = cv2.VideoCapture(self.file_path)
        fps = cap.get(cv2.CAP_PROP_FPS)
        cap.set(cv2.CAP_PROP_POS_FRAMES, int(fps * frame_time_sec))
        ret, frame = cap.read()
        cap.release()
        
        if not ret:
            print("[!] æ— æ³•è¯»å–è¯¥å¸§")
            return

        original_img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        temp_filename = "temp_ela.jpg"
        original_img.save(temp_filename, "JPEG", quality=90)
        compressed_img = Image.open(temp_filename)
        
        ela_img = ImageChops.difference(original_img, compressed_img)
        stat = ImageStat.Stat(ela_img)
        mean_diff = sum(stat.mean) / len(stat.mean)
        tamper_score = min(mean_diff * 10, 100)
        
        print(f"    [ELA é‡åŒ–è¯„åˆ†]")
        print(f"    - å¼‚å¸¸ç³»æ•°: {tamper_score:.2f}/100")
        
        if tamper_score > 30:
            print("    - âš ï¸ è­¦å‘Š: æ£€æµ‹åˆ°å¼‚å¸¸çš„å‹ç¼©ä¼ªå½±ï¼Œè¯¥å¸§å¯èƒ½åŒ…å«åˆæˆå…ƒç´ ï¼")
        else:
            print("    - çŠ¶æ€: å‹ç¼©ç‰¹å¾å‡åŒ€ï¼Œæœªè§æ˜æ˜¾å±€éƒ¨ç¯¡æ”¹ã€‚")

        extrema = ela_img.getextrema()
        max_diff_val = max([ex[1] for ex in extrema])
        scale = 255.0 / (max_diff_val if max_diff_val > 0 else 1) * 15 
        ela_img = ImageEnhance.Brightness(ela_img).enhance(scale)
        
        output_filename = f"ela_check.png"
        
        plt.figure(figsize=(10, 5))
        plt.subplot(1, 2, 1)
        plt.title("åŸå§‹å¸§")
        plt.imshow(original_img)
        plt.axis('off')
        plt.subplot(1, 2, 2)
        plt.title(f"ELA (å¼‚å¸¸åˆ†: {tamper_score:.1f})")
        plt.imshow(ela_img)
        plt.axis('off')
        
        try:
            plt.savefig(output_filename)
            print(f"    [å›¾ç‰‡] ELAåˆ†æå›¾å·²ä¿å­˜è‡³: {output_filename}")
        except Exception:
            pass
        
        if os.path.exists(temp_filename):
            try: os.remove(temp_filename)
            except: pass

    def analyze_audio_smart(self):
        """
        æ™ºèƒ½ç‰ˆï¼šéŸ³é¢‘ç‰¹å¾åˆ†æ (å¼•å…¥ MFCC å£°å­¦ç‰¹å¾)
        å¢å¼ºå¯¹â€œéŸ³è‰²/ç¯å¢ƒéŸ³â€çªå˜çš„æ£€æµ‹èƒ½åŠ›ã€‚
        """
        if not self.has_audio:
            print("\n--- [4] éŸ³é¢‘åˆ†æè·³è¿‡ (æ— éŸ³é¢‘æµ) ---")
            return []

        print("\n--- [4] å¼€å§‹éŸ³é¢‘ç‰¹å¾æ˜¾è‘—æ€§åˆ†æ (èƒ½é‡ + MFCCå£°çº¹) ---")
        try:
            with warnings.catch_warnings():
                warnings.filterwarnings("ignore")
                # åŠ è½½éŸ³é¢‘
                duration_to_load = min(self.duration, 180) 
                y, sr = librosa.load(self.file_path, duration=duration_to_load)
            
            # --- ç‰¹å¾æå– ---
            
            # 1. Onset Strength (èƒ½é‡çªå˜) - æ•æ‰ç¡¬å‰ªè¾‘
            onset_env = librosa.onset.onset_strength(y=y, sr=sr)
            
            # 2. MFCC Delta (å£°çº¹/éŸ³è‰²çªå˜) - æ•æ‰ç¯å¢ƒå˜åŒ–
            # MFCC åæ˜ äº†éŸ³é¢‘çš„éŸ³è‰²ç‰¹å¾ï¼Œä¸åŒå½•éŸ³ç¯å¢ƒ MFCC ä¼šæœ‰æ˜¾è‘—å·®å¼‚
            mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)
            # è®¡ç®—æ¯ä¸€å¸§ä¸å‰ä¸€å¸§çš„å·®å¼‚ (Delta)
            mfcc_delta = librosa.feature.delta(mfcc)
            # è®¡ç®—æ¯å¸§å˜åŒ–çš„ L2 èŒƒæ•°ï¼Œå¾—åˆ°ä¸€ä¸ªæ ‡é‡åºåˆ—
            mfcc_change = np.linalg.norm(mfcc_delta, axis=0)
            
            # --- å½’ä¸€åŒ–ä¸èåˆ ---
            
            # è°ƒæ•´é•¿åº¦ä¸€è‡´ (MFCC å¸§æ•°é€šå¸¸æ¯” Onset å°‘ä¸€ç‚¹ç‚¹ï¼Œå¯¹é½ä¸€ä¸‹)
            min_len = min(len(onset_env), len(mfcc_change))
            onset_env = onset_env[:min_len]
            mfcc_change = mfcc_change[:min_len]
            times = librosa.frames_to_time(np.arange(min_len), sr=sr)
            
            # å½’ä¸€åŒ–åˆ° 0-1
            def normalize(arr):
                return (arr - np.min(arr)) / (np.max(arr) - np.min(arr) + 1e-6)
            
            norm_onset = normalize(onset_env)
            norm_mfcc = normalize(mfcc_change)
            
            # ç»¼åˆè¯„åˆ†ï¼š40% èƒ½é‡æƒé‡ + 60% éŸ³è‰²æƒé‡
            # åŠ å¤§ MFCC æƒé‡æœ‰åŠ©äºå‘ç°é‚£äº›éŸ³é‡æ²¡å˜ä½†éŸ³è‰²å˜äº†çš„æ‹¼æ¥
            combined_score = 0.4 * norm_onset + 0.6 * norm_mfcc
            
            # --- å³°å€¼æ’åº ---
            
            points = []
            for i, score in enumerate(combined_score):
                points.append((times[i], score))
            
            # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
            sorted_points = sorted(points, key=lambda x: x[1], reverse=True)
            
            final_audio_cuts = []
            avg_score = np.mean(combined_score)
            std_score = np.std(combined_score)
            # é™ä½é˜ˆå€¼ï¼Œæ›´çµæ•åœ°æ•æ‰å¼‚å¸¸
            threshold_base = avg_score + 2.0 * std_score
            
            for t, score in sorted_points:
                if score < threshold_base: 
                    continue
                # è·ç¦»è¿‡æ»¤ (1ç§’å†…åªæŠ¥æœ€å¼ºç‚¹)
                is_near = False
                for existing_t, _ in final_audio_cuts:
                    if abs(t - existing_t) < 1.0:
                        is_near = True
                        break
                if not is_near:
                    final_audio_cuts.append((t, score))
                    if len(final_audio_cuts) >= 8: # å¢åŠ æ£€æµ‹ç‚¹æ•°é‡ï¼Œé¿å…é—æ¼
                        break
            
            print(f"    [éŸ³é¢‘åˆ†æç»“æœ]")
            if not final_audio_cuts:
                print("    - ç»“æœ: éŸ³é¢‘ç‰¹å¾å¹³ç¨³ã€‚")
                return []
            else:
                print(f"    - ç»“æœ: å‘ç°å£°å­¦ç‰¹å¾æ–­å±‚ï¼ŒæŒ‰ã€æ˜¾è‘—æ€§ã€‘æ’åºï¼š")
                for i, (t, score) in enumerate(final_audio_cuts):
                    print(f"      [{i+1}] æ—¶é—´: {format_timestamp(t)} | çªå˜åˆ†: {score:.3f}")
            
            # ç»˜å›¾
            plt.figure(figsize=(12, 8))
            
            plt.subplot(2, 1, 1)
            librosa.display.waveshow(y, sr=sr, alpha=0.6)
            plt.title('æ³¢å½¢å›¾ (Waveform) - çº¢è‰²è™šçº¿ä¸ºç–‘ä¼¼ç‚¹')
            for t, _ in final_audio_cuts:
                plt.axvline(x=t, color='r', linestyle='--', alpha=0.8)

            plt.subplot(2, 1, 2)
            plt.plot(times, combined_score, label='ç»¼åˆç‰¹å¾çªå˜ (Score)', color='green')
            plt.title('å£°å­¦ç‰¹å¾å˜åŒ–ç‡ (MFCC + Energy) - å³°å€¼å³ä¸ºæ–­å±‚')
            plt.axhline(y=threshold_base, color='gray', linestyle=':', label='åŠ¨æ€é˜ˆå€¼')
            for t, _ in final_audio_cuts:
                plt.axvline(x=t, color='r', linestyle='--', alpha=0.5)
            plt.legend()
            
            plt.tight_layout()
            plt.savefig("audio_check_smart.png")
            print(f"    [å›¾ç‰‡] è¯¦ç»†åˆ†æå›¾å·²ä¿å­˜è‡³: audio_check_smart.png")
            
            return [t for t, s in final_audio_cuts]
            
        except Exception as e:
            print(f"[!] éŸ³é¢‘åˆ†æä¸­æ–­: {e}")
            return []

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("-f", "--file", type=str, help="æ–‡ä»¶è·¯å¾„")
    args = parser.parse_args()

    target_file = args.file
    if not target_file:
        print("\n=== éŸ³è§†é¢‘æ‹¼æ¥å–è¯å·¥å…· (MFCCå£°çº¹å¢å¼ºç‰ˆ) ===")
        print("è¯·è¾“å…¥æ–‡ä»¶è·¯å¾„ (æ”¯æŒ MP4, AVI, MP3, WAV ç­‰):")
        target_file = input(">>> ").strip().strip("'").strip('"')

    if target_file and os.path.exists(target_file):
        tool = MediaForensicsTool(target_file)
        
        # 1. å…ƒæ•°æ®åŠç±»å‹æ£€æµ‹
        tool.analyze_metadata()
        
        # 2. è§†é¢‘æ£€æµ‹ (å¦‚æœæ˜¯è§†é¢‘)
        video_cuts = []
        if tool.has_video:
            video_cuts = tool.detect_video_cuts_smart()
            
            check_points = [1.0]
            if video_cuts:
                check_points = video_cuts[:2] 
                print(f"\n[i] é‡ç‚¹å¯¹å‰ {len(check_points)} ä¸ªå¯ç–‘ç‚¹è¿›è¡Œ ELA ç¯¡æ”¹éªŒè¯...")
            
            for t in check_points:
                tool.perform_ela_on_frame(t)
        else:
            print("\n[i] çº¯éŸ³é¢‘æ–‡ä»¶ï¼Œè·³è¿‡è§†é¢‘ç”»é¢åˆ†ææ¨¡å—ã€‚")
        
        # 3. éŸ³é¢‘æ£€æµ‹
        audio_cuts = tool.analyze_audio_smart()
        
        # 4. ç»¼åˆåˆ¤å®š
        print("\n=== ğŸ æœ€ç»ˆå–è¯ç»“è®º (åŸºäº Top æ’å) ===")
        
        if tool.has_video:
            primary_match = False
            if video_cuts and audio_cuts:
                v_top1 = video_cuts[0]
                for a_cut in audio_cuts[:3]: 
                    if abs(v_top1 - a_cut) < 1.0:
                        print(f"âœ… ã€ç¡®å‡¿è¯æ®ã€‘ è§†é¢‘æœ€å¼ºçªå˜ç‚¹ä¸éŸ³é¢‘æ–­å±‚é‡åˆï¼")
                        print(f"   >>> æ‹¼æ¥ç‚¹æå¤§æ¦‚ç‡åœ¨: {format_timestamp(v_top1)} <<<")
                        primary_match = True
                        break
            
            if not primary_match:
                if video_cuts: print(f"âš ï¸ ã€ç–‘ä¼¼æ‹¼æ¥ã€‘ è§†é¢‘ç”»é¢åœ¨ {format_timestamp(video_cuts[0])} å¤„æœ‰æœ€å¤§çªå˜ã€‚")
                if audio_cuts: print(f"âš ï¸ ã€ç–‘ä¼¼æ‹¼æ¥ã€‘ éŸ³é¢‘æ³¢å½¢åœ¨ {format_timestamp(audio_cuts[0])} å¤„æœ‰æœ€å¤§æ–­å±‚ã€‚")
        elif tool.has_audio:
            # çº¯éŸ³é¢‘æ¨¡å¼ä¸‹çš„ç»“è®º
            if audio_cuts:
                print(f"âš ï¸ ã€ç–‘ä¼¼å‰ªè¾‘ã€‘ æ£€æµ‹åˆ°éŸ³é¢‘å£°çº¹å­˜åœ¨ {len(audio_cuts)} å¤„æ˜¾è‘—æ–­å±‚/çªå˜ã€‚")
                print(f"   æœ€æ˜¾è‘—çš„æ‹¼æ¥ç‚¹å¯èƒ½åœ¨: {format_timestamp(audio_cuts[0])}")
                print("   è¯·å‚è€ƒç”Ÿæˆçš„ç‰¹å¾å›¾ (audio_check_smart.png) è§‚å¯Ÿç»¿è‰²æ›²çº¿çš„å°–å³°ã€‚")
            else:
                print("âœ… ã€ä½é£é™©ã€‘ éŸ³é¢‘æ³¢å½¢ä¸å£°çº¹è¿ç»­æ€§è‰¯å¥½ï¼Œæœªæ£€æµ‹åˆ°æ˜æ˜¾çš„ç¡¬å‰ªè¾‘ç—•è¿¹ã€‚")

    else:
        print("[!] æ–‡ä»¶ä¸å­˜åœ¨")
